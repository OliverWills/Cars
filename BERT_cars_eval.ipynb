{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOwvK9vP5zTVT4n7HSnQPc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OliverWills/Cars/blob/main/BERT_cars_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHehOTqWgwdW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, drop_rate=0.2, freeze_bert=False):\n",
        "\n",
        "        super(BertRegressor, self).__init__()\n",
        "        D_in, D_out = 768, 1\n",
        "\n",
        "        self.bert = \\\n",
        "                   BertModel.from_pretrained('bert-base-cased')\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(D_in, D_out))\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "\n",
        "        outputs = self.bert(input_ids, attention_masks)\n",
        "        class_label_output = outputs[1]\n",
        "        outputs = self.regressor(class_label_output)\n",
        "        return outputs\n",
        "\n",
        "model = BertRegressor(drop_rate=0.2)"
      ],
      "metadata": {
        "id": "xcUtpVwog0BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(PATH)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "pQcQBDpLg51A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive and read data from CSV file\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv(\"/content/drive/My Drive/BMW_cleansed.csv\")"
      ],
      "metadata": {
        "id": "G4dJq7Uug8Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['id']=data['Link'].str.split('/').str[-1]\n",
        "data['age']=datetime.datetime.now().year-data['Year']\n",
        "data['combined']=data['id']+\\\n",
        "  \" This is \"+data['Title']+\\\n",
        "  \". It is located in \"+data['Location']+\\\n",
        "  \". The car is \"+data['age'].astype(str)+\\\n",
        "  \" years old. It has an engine size of \"+data['Engine Size'].astype(str)+\\\n",
        "  \"cc. It uses \"+data['Fuel Type']+\\\n",
        "  \" fuel. It has done \"+data['Mileage'].astype(str)+\\\n",
        "  \" miles. \"+data['Description']\n",
        "data=data.dropna()\n",
        "Q1, Q3 = data.Price.quantile([0.25,0.75])\n",
        "IQR = Q3 - Q1\n",
        "limit = Q3 + 1.5 * IQR\n",
        "data=data[data['Price']<limit]\n",
        "data = data[['Price','combined']]\n",
        "descriptions=data['combined'].tolist()"
      ],
      "metadata": {
        "id": "mwuHGv25hGVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and define tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# encode descriptions using tokenizer\n",
        "encoded_corpus = tokenizer(text=descriptions,\n",
        "  add_special_tokens=True,\n",
        "  padding='max_length',\n",
        "  truncation='longest_first',\n",
        "  max_length=512,\n",
        "  return_attention_mask=True)"
      ],
      "metadata": {
        "id": "3C4l6QjdhrUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input ids and attention masks\n",
        "input_ids = encoded_corpus['input_ids']\n",
        "attention_mask = encoded_corpus['attention_mask']\n",
        "\n",
        "input_ids = np.array(input_ids)\n",
        "attention_mask = np.array(attention_mask)\n",
        "labels = data['Price'].to_numpy()"
      ],
      "metadata": {
        "id": "mpLagqtehsLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and test inputs and labels\n",
        "test_size = 0.1\n",
        "seed = 42\n",
        "\n",
        "train_valid_inputs, test_inputs, train_valid_labels, test_labels = \\\n",
        "            train_test_split(input_ids, labels, test_size=test_size,\n",
        "                             random_state=seed)\n",
        "\n",
        "train_inputs, valid_inputs, train_labels, valid_labels = \\\n",
        "            train_test_split(train_valid_inputs, train_valid_labels, test_size=test_size,\n",
        "                             random_state=seed)\n",
        "\n",
        "train_valid_masks, test_masks, _, _ = train_test_split(attention_mask,\n",
        "                                        labels, test_size=test_size,\n",
        "                                        random_state=seed)\n",
        "\n",
        "train_masks, valid_masks, _, _ = train_test_split(train_valid_masks,\n",
        "                                        train_valid_labels, test_size=test_size,\n",
        "                                        random_state=seed)"
      ],
      "metadata": {
        "id": "bsEZsqnshv2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and create train and test dataloaders\n",
        "batch_size = 16\n",
        "def create_dataloaders(inputs, masks, labels, batch_size):\n",
        "    input_tensor = torch.tensor(inputs)\n",
        "    mask_tensor = torch.tensor(masks)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_tensor, mask_tensor,\n",
        "                            labels_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size,\n",
        "                            shuffle=True)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "rS0CVzhFi2lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = create_dataloaders(test_inputs, test_masks,\n",
        "                                     test_labels, batch_size)"
      ],
      "metadata": {
        "id": "R_2niPXtjJI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    output = []\n",
        "    for batch in dataloader:\n",
        "        batch_inputs, batch_masks, _ = \\\n",
        "                                  tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            output += model(batch_inputs,\n",
        "                            batch_masks).view(1,-1).tolist()[0]\n",
        "    return output"
      ],
      "metadata": {
        "id": "pVACxU4TjMvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "XCAVx582jR1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_scaled = predict(model, test_dataloader, device)"
      ],
      "metadata": {
        "id": "X0j2ZZTojXAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.array(test_labels)\n",
        "y_pred_scaled = np.array(y_pred_scaled)\n",
        "\n",
        "y_pred = price_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))"
      ],
      "metadata": {
        "id": "7pQJ1M3Sjfrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('y test')\n",
        "plt.ylabel('y pred')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sf2PVrN9jkpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(y_pred, columns=['y_pred'])\n",
        "results_df['y_test']=pd.Series(y_test)\n",
        "results_df['price_diff']=results_df['y_pred']-results_df['y_test']\n",
        "results_df.sort_values('price_diff', axis=0, ascending=False, inplace=True)\n",
        "print(results_df.head(10))"
      ],
      "metadata": {
        "id": "cw83Qd_8jsuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs\n",
        "test_labels"
      ],
      "metadata": {
        "id": "s-bN8xtNkItK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}